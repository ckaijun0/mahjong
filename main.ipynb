{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7702c9a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'discard_tile' from 'ipynb.fs.full.mahjong_rules' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Counter\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Note: To use this import: pip install ipynb\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mipynb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfull\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmahjong_rules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m discard_tile, draw_tile, update_state, display_tiles\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mipynb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfull\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmahjong_rules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m initialize_simple_mahjong, is_winning_hand\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'discard_tile' from 'ipynb.fs.full.mahjong_rules' (unknown location)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "from collections import Counter\n",
    "# Note: To use this import: pip install ipynb\n",
    "from ipynb.fs.full.mahjong_rules import discard_tile, draw_tile, update_state, display_tiles\n",
    "from ipynb.fs.full.mahjong_rules import initialize_simple_mahjong, is_winning_hand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6c715b",
   "metadata": {},
   "source": [
    "### Initialize Game State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "865e3005",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'initialize_simple_mahjong' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m game_state \u001b[38;5;241m=\u001b[39m \u001b[43minitialize_simple_mahjong\u001b[49m()\n\u001b[1;32m      2\u001b[0m display_tiles(game_state)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'initialize_simple_mahjong' is not defined"
     ]
    }
   ],
   "source": [
    "game_state = initialize_simple_mahjong()\n",
    "display_tiles(game_state)\n",
    "# state1 = copy.deepcopy(game_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6aff4500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# policy.N_dict\n",
    "policy.N[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dedddaec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MonteCarloTreeSearch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mMonteCarloTreeSearch\u001b[49m(game_state,\u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MonteCarloTreeSearch' is not defined"
     ]
    }
   ],
   "source": [
    "MonteCarloTreeSearch(game_state,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fd897abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7947700045660605086"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = random.choices(np.arange(33*4),k=14)\n",
    "state = np.zeros([33,4])\n",
    "for i in random_seed:\n",
    "    # int(i/4) gives tile no., i%4 gives copy no.\n",
    "    state[int(i/4),i%4]=1\n",
    "s_hash = hash(state.tobytes())\n",
    "s_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "59b7d64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy(object):\n",
    "    def __init__(self,n_tiles,m_simulations,player_hand_size):\n",
    "        # Maximum number of moves is about n_tiles\n",
    "        self.N = np.zeros([m_simulations*n_tiles,player_hand_size])\n",
    "        self.Q = np.zeros([m_simulations*n_tiles,player_hand_size])\n",
    "        self.state_dict = {}\n",
    "        self.N_dict = {}\n",
    "        self.n_tiles = n_tiles\n",
    "        # Hyperparameters\n",
    "        self.exploration_parameter = 1\n",
    "        self.depth = 3\n",
    "        self.gamma = 0.95\n",
    "    \n",
    "def MonteCarloTreeSearch(state,m_simulations):\n",
    "    # define policy globally so that dont need to keep passing it around\n",
    "    global policy\n",
    "    policy = Policy(m_simulations=m_simulations,\n",
    "                    n_tiles = len(state)*len(state[0]), \n",
    "                    player_hand_size=8)\n",
    "    \n",
    "    s_hash = hash(state.tobytes())\n",
    "    policy.state_dict.update({0:state})\n",
    "    policy.N_dict.update({s_hash:0})\n",
    "    \n",
    "    for k in range(m_simulations):\n",
    "        simulate(state, policy.depth)\n",
    "    \n",
    "    # state = 2D array representing mahjong game state np.array([33,4])\n",
    "    s_hash = hash(state.tobytes()) # s_hash = state converted to bytes (e.g., -6026512037226545482, 7947700045660605086)\n",
    "    s = policy.N_dict[s_hash] # s = index (e.g., 1,2,3,..)\n",
    "    \n",
    "    # policy.Q[s,possible_a] is updated globally in the \"simulate\" function\n",
    "    optimal_action = np.argmax(policy.Q[s,:])\n",
    "    \n",
    "    return optimal_action\n",
    "\n",
    "def simulate(state, depth):\n",
    "    if is_winning_hand(state): # NEED FUNCTION #\n",
    "        return get_reward(state) # NEED FUNCTION #\n",
    "\n",
    "    if depth <= 0:\n",
    "        return get_reward(state)\n",
    "      \n",
    "    s_hash = hash(state.tobytes())\n",
    "    if s_hash not in policy.N_dict.keys():\n",
    "        new_index = max(policy.N_dict.values())+1\n",
    "        policy.state_dict.update({new_index:state})\n",
    "        policy.N_dict.update({s_hash:new_index})\n",
    "\n",
    "    s = policy.N_dict[s_hash]\n",
    "    \n",
    "    a = explore(s)\n",
    "    \n",
    "    # Return a new state - discard tile and draw tile. Also return the reward for that state\n",
    "    next_state, reward = update_state(state, a) # NEED FUNCTION #\n",
    "    \n",
    "    q = reward + policy.gamma*simulate(next_state, depth-1)\n",
    "    policy.N[s,a] += 1\n",
    "    policy.Q[s,a] += (q-Q[s,a])/policy.N[s,a]\n",
    "    return q # q is returned to itself recursively, but not to MonteCarloTreeSearch\n",
    "\n",
    "# np.inf*(N[s,a] == 0) returns infinity if the state has yet to be explored\n",
    "# more efficient version that returns warning message: np.inf*(Nsa == 0) + np.sqrt(np.log(Ns)/Nsa)\n",
    "def exploration_bonus(Nsa,Ns):\n",
    "    if Nsa == 0:\n",
    "        return np.inf\n",
    "    else:\n",
    "        return np.sqrt(np.log(Ns)/Nsa)\n",
    "\n",
    "# equation (9.1) - Q(s,a)+c*sqrt(logN(s)/N(s,a))\n",
    "def explore(s):\n",
    "    Ns = np.sum(policy.N[s,:])\n",
    "    policy.Q[s,:] = policy.exploration_parameter * exploration_bonus(policy.N[s,:],Ns)\n",
    "    explore_action = np.argmax(policy.Q[s,:])\n",
    "    return explore_action\n",
    "\n",
    "def random_policy(state):\n",
    "    while not is_winning_hand(state):\n",
    "        try:\n",
    "            state = choose_random_action(state)\n",
    "        except IndexError:\n",
    "            raise Exception(\"Non-terminal state has no possible actions: \" + str(state))\n",
    "    return get_reward(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "001f61a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "exploration_bonus(Nsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203792fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "7122adb744740e507ab43c807646a989cfd0e5a91b89232016711cafc2d838ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
