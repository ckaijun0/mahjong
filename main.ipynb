{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7702c9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "from collections import Counter\n",
    "# Note: To use this import: pip install ipynb\n",
    "from ipynb.fs.full.mahjong_rules import discard_tile, draw_tile, update_state, display_tiles\n",
    "from ipynb.fs.full.mahjong_rules import initialize_simple_mahjong, is_winning_hand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6c715b",
   "metadata": {},
   "source": [
    "### Initialize Game State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "865e3005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~Player Hand~\n",
      "['1 Tong', '3 Tong', '4 Tong', '6 Tong', '7 Tong', '7 Tong', '8 Tong', '1 Wan']\n",
      "--------------\n",
      "~Discard Pile~\n",
      "[]\n",
      "--------------\n",
      "~Draw Pile~\n",
      "tile count = 124\n"
     ]
    }
   ],
   "source": [
    "game_state = initialize_simple_mahjong()\n",
    "display_tiles(game_state)\n",
    "# state1 = copy.deepcopy(game_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6aff4500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# policy.N_dict\n",
    "policy.N[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dedddaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\junvi\\AppData\\Local\\Temp\\ipykernel_12724\\1868645214.py:64: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.inf*(Nsa == 0) + np.sqrt(np.log(Ns)/Nsa)\n",
      "C:\\Users\\junvi\\AppData\\Local\\Temp\\ipykernel_12724\\1868645214.py:64: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.inf*(Nsa == 0) + np.sqrt(np.log(Ns)/Nsa)\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'q' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12724\\2469823858.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mMonteCarloTreeSearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12724\\1868645214.py\u001b[0m in \u001b[0;36mMonteCarloTreeSearch\u001b[1;34m(state, m_simulations)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm_simulations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0msimulate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m# state = 2D array representing mahjong game state np.array([33,4])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12724\\1868645214.py\u001b[0m in \u001b[0;36msimulate\u001b[1;34m(state, depth)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# NEED FUNCTION #\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m     \u001b[0mq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreward\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msimulate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12724\\1868645214.py\u001b[0m in \u001b[0;36msimulate\u001b[1;34m(state, depth)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# NEED FUNCTION #\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m     \u001b[0mq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreward\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msimulate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12724\\1868645214.py\u001b[0m in \u001b[0;36msimulate\u001b[1;34m(state, depth)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# NEED FUNCTION #\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m     \u001b[0mq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreward\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msimulate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12724\\1868645214.py\u001b[0m in \u001b[0;36msimulate\u001b[1;34m(state, depth)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdepth\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0ms_hash\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhash\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'q' referenced before assignment"
     ]
    }
   ],
   "source": [
    "MonteCarloTreeSearch(game_state,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fd897abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7947700045660605086"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = random.choices(np.arange(33*4),k=14)\n",
    "state = np.zeros([33,4])\n",
    "for i in random_seed:\n",
    "    # int(i/4) gives tile no., i%4 gives copy no.\n",
    "    state[int(i/4),i%4]=1\n",
    "s_hash = hash(state.tobytes())\n",
    "s_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "59b7d64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy(object):\n",
    "    def __init__(self,n_tiles,m_simulations,player_hand_size):\n",
    "        # Maximum number of moves is about n_tiles\n",
    "        self.N = np.zeros([m_simulations*n_tiles,player_hand_size])\n",
    "        self.Q = np.zeros([m_simulations*n_tiles,player_hand_size])\n",
    "        self.state_dict = {}\n",
    "        self.N_dict = {}\n",
    "        self.n_tiles = n_tiles\n",
    "        # Hyperparameters\n",
    "        self.exploration_parameter = 1\n",
    "        self.depth = 3\n",
    "        self.gamma = 0.95\n",
    "    \n",
    "def MonteCarloTreeSearch(state,m_simulations):\n",
    "    # define policy globally so that dont need to keep passing it around\n",
    "    global policy\n",
    "    policy = Policy(m_simulations=m_simulations,\n",
    "                    n_tiles = len(state)*len(state[0]), \n",
    "                    player_hand_size=8)\n",
    "    \n",
    "    s_hash = hash(state.tobytes())\n",
    "    policy.state_dict.update({0:state})\n",
    "    policy.N_dict.update({s_hash:0})\n",
    "    \n",
    "    for k in range(m_simulations):\n",
    "        simulate(state, policy.depth)\n",
    "    \n",
    "    # state = 2D array representing mahjong game state np.array([33,4])\n",
    "    s_hash = hash(state.tobytes()) # s_hash = state converted to bytes (e.g., -6026512037226545482, 7947700045660605086)\n",
    "    s = policy.N_dict[s_hash] # s = index (e.g., 1,2,3,..)\n",
    "    \n",
    "    # policy.Q[s,possible_a] is updated globally in the \"simulate\" function\n",
    "    optimal_action = np.argmax(policy.Q[s,:])\n",
    "    \n",
    "    return optimal_action\n",
    "\n",
    "def simulate(state, depth):\n",
    "    if is_winning_hand(state): # NEED FUNCTION #\n",
    "        return get_reward(state) # NEED FUNCTION #\n",
    "\n",
    "    if depth <= 0:\n",
    "        return q\n",
    "      \n",
    "    s_hash = hash(state.tobytes())\n",
    "    if s_hash not in policy.N_dict.keys():\n",
    "        new_index = max(policy.N_dict.values())+1\n",
    "        policy.state_dict.update({new_index:state})\n",
    "        policy.N_dict.update({s_hash:new_index})\n",
    "\n",
    "    s = policy.N_dict[s_hash]\n",
    "    \n",
    "    a = explore(s)\n",
    "    \n",
    "    # Return a new state - discard tile and draw tile. Also return the reward for that state\n",
    "    next_state, reward = update_state(state, a) # NEED FUNCTION #\n",
    "    \n",
    "    q = reward + policy.gamma*simulate(next_state, depth-1)\n",
    "    policy.N[s,a] += 1\n",
    "    policy.Q[s,a] += (q-Q[s,a])/policy.N[s,a]\n",
    "    return q # q is returned to itself recursively, but not to MonteCarloTreeSearch\n",
    "\n",
    "# np.inf*(N[s,a] == 0) returns infinity if the state has yet to be explored\n",
    "# more efficient version that returns warning message: np.inf*(Nsa == 0) + np.sqrt(np.log(Ns)/Nsa)\n",
    "def exploration_bonus(Nsa,Ns):\n",
    "    if Nsa == 0:\n",
    "        return np.inf\n",
    "    else:\n",
    "        return np.sqrt(np.log(Ns)/Nsa)\n",
    "\n",
    "# equation (9.1) - Q(s,a)+c*sqrt(logN(s)/N(s,a))\n",
    "def explore(s):\n",
    "    Ns = np.sum(policy.N[s,:])\n",
    "    policy.Q[s,:] = policy.exploration_parameter * exploration_bonus(policy.N[s,:],Ns)\n",
    "    explore_action = np.argmax(policy.Q[s,:])\n",
    "    return explore_action\n",
    "\n",
    "def random_policy(state):\n",
    "    while not is_winning_hand(state):\n",
    "        try:\n",
    "            state = choose_random_action(state)\n",
    "        except IndexError:\n",
    "            raise Exception(\"Non-terminal state has no possible actions: \" + str(state))\n",
    "    return get_reward(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "001f61a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "exploration_bonus(Nsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203792fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7122adb744740e507ab43c807646a989cfd0e5a91b89232016711cafc2d838ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
