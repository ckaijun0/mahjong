{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "171af0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a589888",
   "metadata": {},
   "source": [
    "### Mahjong State Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d5e8d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "mahjong_dict = {0:'1 Tong',1:'2 Tong',2:'3 Tong',3:'4 Tong',4:'5 Tong',5:'6 Tong',6:'7 Tong',7:'8 Tong',8:'9 Tong',\n",
    "              9:'1 Wan',10:'2 Wan',11:'3 Wan',12:'4 Wan',13:'5 Wan',14:'6 Wan',15:'7 Wan',16:'8 Wan',17:'9 Wan',\n",
    "              18:'1 Suo',19:'2 Suo',20:'3 Suo',21:'4 Suo',22:'5 Suo',23:'6 Suo',24:'7 Suo',25:'8 Suo',26:'9 Suo',\n",
    "              27:'Dong',28:'Nan',29:'Xi',30:'Bei',\n",
    "              31:'Bai_Ban',32:'Fa_Cai',33:'Hong_Zhong'}\n",
    "\n",
    "def initialize_mahjong():\n",
    "    random_seed = random.sample(np.arange(33*4).tolist(),14)\n",
    "    state = np.zeros([33,4])\n",
    "    for i in random_seed:\n",
    "        # int(i/4) gives tile no., i%4 gives copy no.\n",
    "        state[int(i/4),i%4]=1\n",
    "    return state\n",
    "\n",
    "simple_mahjong_dict = {0:'1 Tong',1:'2 Tong',2:'3 Tong',3:'4 Tong',4:'5 Tong',5:'6 Tong',\n",
    "                       6:'1 Wan',7:'2 Wan',8:'3 Wan',9:'4 Wan',10:'5 Wan',11:'6 Wan'}\n",
    "\n",
    "def initialize_simple_mahjong():\n",
    "    random_seed = random.sample(np.arange(12*4).tolist(),8)\n",
    "    state = np.zeros([12,4])\n",
    "    for i in random_seed:\n",
    "        # int(i/4) gives tile no., i%4 gives copy no.\n",
    "        state[int(i/4),i%4]=1\n",
    "    return state\n",
    "\n",
    "# Converts a value between 0 and 13 to the tile to discard in that state\n",
    "def discard_tile(state,action):\n",
    "    # action = value between 0 and 13\n",
    "    tile_ind = [i for i, x in enumerate(state.flatten()) if x == 1]\n",
    "    # e.g. tile_ind [1, 8, 10, 11, 27, 39, 72, 73, 82, 88, 98, 115, 118]\n",
    "    # action = 2\n",
    "    # tile_ind[action] = 10\n",
    "    return int(tile_ind[action]/4), tile_ind[action]%4\n",
    "\n",
    "# Select a random index that is of value 0 (draw_pile) to the tile to discard in that state\n",
    "def draw_tile(state):\n",
    "    tile_ind = [i for i, x in enumerate(state.flatten()) if x == 0]\n",
    "    rand_tile = random.choice(tile_ind)\n",
    "    return int(rand_tile/4), rand_tile%4\n",
    "\n",
    "def is_winning_hand(state):\n",
    "    return False # True or False\n",
    "\n",
    "def get_reward(state):\n",
    "    ### FILL IN ###\n",
    "    ### To include both Mahjong scoring rules and artificial tiny reward for 'pong's\n",
    "    return 0\n",
    "\n",
    "# Discard and randomly draw a tile\n",
    "def update_state(state,action):\n",
    "    x,y = discard_tile(state,action)\n",
    "    state[x,y] = 10 # discard pile = 10\n",
    "    x,y = draw_tile(state)\n",
    "    state[x,y] = 1 # player hand = 1\n",
    "    # compute reward of updated state\n",
    "    reward = get_reward(state)\n",
    "    return state, reward\n",
    "\n",
    "# convert a 2D array state to string (for dictionary comparison purposes)\n",
    "def state_to_string(state):\n",
    "    state_string = ''\n",
    "    state[state==10] = 2 \n",
    "    for i in state.flatten():\n",
    "        state_string += str(int(i))\n",
    "    return state_string\n",
    "\n",
    "# Use this function to output the entire state to see \n",
    "# Displays player hand & discard pile\n",
    "# Does not display draw pile (only shows how many tiles remaining)\n",
    "def display_tiles(state):\n",
    "    print('~Player Hand~')\n",
    "    player1_hand_ind = [i for i, x in enumerate(state.flatten()) if x == 1]\n",
    "    player1_hand = [mahjong_dict.get(int(key/4)) for key in player1_hand_ind]\n",
    "    print(player1_hand)\n",
    "    print('--------------')\n",
    "    print('~Discard Pile~')\n",
    "    discard_pile_ind = [i for i, x in enumerate(state.flatten()) if x == 10]\n",
    "    discard_pile = [mahjong_dict.get(int(key/4)) for key in discard_pile_ind]\n",
    "    print(discard_pile)\n",
    "    print('--------------')\n",
    "    print('~Draw Pile~')\n",
    "    print('tile count =',len(game_state)*4-len(player1_hand)-len(discard_pile))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98067eb",
   "metadata": {},
   "source": [
    "### Monte Carlo Tree Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9d29b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy(object):\n",
    "    def __init__(self,n_tiles,player_hand_size):\n",
    "        # Hyperparameters\n",
    "        self.exploration_parameter = 1\n",
    "        self.m_simulations = 2\n",
    "        self.depth = 3\n",
    "        self.gamma = 0.95\n",
    "        # Maximum number of moves is about n_tiles\n",
    "        # N = count (number of times an state-action pair is visited)\n",
    "        self.N = np.zeros([self.m_simulations*n_tiles,player_hand_size]) \n",
    "        self.Q = np.zeros([self.m_simulations*n_tiles,player_hand_size])\n",
    "        self.state_dict = {}\n",
    "        self.n_tiles = n_tiles\n",
    "\n",
    "def create_policy(state):\n",
    "    global policy\n",
    "    policy = Policy(n_tiles = len(state)*len(state[0]), \n",
    "                    player_hand_size=np.count_nonzero(game_state==1))\n",
    "        \n",
    "def MonteCarloTreeSearch(state):  \n",
    "    state_string = state_to_string(state)\n",
    "    if not policy.state_dict: # if dict empty, add first key-value entry\n",
    "        policy.state_dict.update({state_string:0})\n",
    "    \n",
    "    for k in range(policy.m_simulations):\n",
    "        simulate(state.copy(), policy.depth)\n",
    "    \n",
    "    # convert state to s, then use that as index to find the action that maximizes Q[s,a] from policy.Q\n",
    "    \n",
    "    # state = 2D array representing mahjong game state np.array([33,4])\n",
    "    s = policy.state_dict[state_string]\n",
    "    \n",
    "    # policy.Q[s,possible_a] is updated globally in the \"simulate\" function\n",
    "    optimal_action = np.argmax(policy.Q[s,:])\n",
    "    \n",
    "    return optimal_action\n",
    "\n",
    "def simulate(state, depth):\n",
    "    if is_winning_hand(state): # NEED FUNCTION #\n",
    "        return get_reward(state) # NEED FUNCTION #\n",
    "\n",
    "    if depth <= 0:\n",
    "        return get_reward(state)\n",
    "      \n",
    "    state_string = state_to_string(state)\n",
    "\n",
    "    # create a dict entry if the state has not been reached before\n",
    "    if state_string not in policy.state_dict.keys():\n",
    "        new_index = max(policy.state_dict.values())+1\n",
    "        policy.state_dict.update({state_string:new_index})\n",
    "    \n",
    "    s = policy.state_dict[state_string]\n",
    "    \n",
    "    a = explore(s)\n",
    "    \n",
    "    # Return a new state - discard tile and draw tile. Also return the reward for that state\n",
    "    next_state, reward = update_state(state.copy(), a) ### WHAT EXACTLY IS THIS REWARD?\n",
    "    \n",
    "    q = reward + policy.gamma*simulate(next_state, depth-1) ### FIND THIS EQUATION\n",
    "    policy.N[s,a] += 1 ### SHOULD THIS BE ABOVE OR BELOW q\n",
    "    policy.Q[s,a] += (q-policy.Q[s,a])/policy.N[s,a]\n",
    "    return q # q is returned to itself recursively, but not to MonteCarloTreeSearch\n",
    "\n",
    "# alternative 1 line version: return (test_m==0)*np.nan_to_num(np.inf) + (test_m!=0)*test_m/np.sum(test_m)\n",
    "def exploration_bonus(Nsa,Ns):\n",
    "    return_array = []\n",
    "    for x in range(len(Nsa)):\n",
    "        if Nsa[x] == 0:\n",
    "            return_array.append(np.nan_to_num(np.inf))\n",
    "        elif Nsa[x] != 0:\n",
    "            return_array.append(np.sqrt(np.log(Nsa[x])/Ns))\n",
    "    return np.array(return_array)\n",
    "\n",
    "# equation (9.1) - Q(s,a)+c*sqrt(logN(s)/N(s,a))\n",
    "def explore(s):\n",
    "    Ns = np.sum(policy.N[s,:])\n",
    "    policy.Q[s,:] = policy.exploration_parameter * exploration_bonus(policy.N[s,:],Ns)\n",
    "    explore_action = np.argmax(policy.Q[s,:])\n",
    "    return explore_action\n",
    "\n",
    "def random_policy(state):\n",
    "    while not is_winning_hand(state):\n",
    "        try:\n",
    "            state = choose_random_action(state)\n",
    "        except IndexError:\n",
    "            raise Exception(\"Non-terminal state has no possible actions: \" + str(state))\n",
    "    return get_reward(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449cb776",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4deca558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_state = initialize_simple_mahjong()\n",
    "create_policy(game_state)\n",
    "MonteCarloTreeSearch(game_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8d5b60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
